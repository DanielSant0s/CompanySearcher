{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CompanySearch_proto.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPsNcaiGQdHqEBgJaU3zmG1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielSant0s/CompanySearcher/blob/main/CompanySearch_proto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBp4XEYcMzRR"
      },
      "outputs": [],
      "source": [
        "# Some imports to do automatic info rewriting\n",
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "!pip install webdriver_manager\n",
        "!pip install fake-useragent\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "import requests\n",
        "import urllib\n",
        "from fake_useragent import UserAgent\n",
        "\n",
        "def get_html(url):\n",
        "        driver.get(url)\n",
        "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "        return soup\n",
        "\n",
        "links = [] # Initiate empty list to capture final results\n",
        "\n",
        "def get_result_link(query):\n",
        "    #query = urllib.parse.quote_plus(query)\n",
        "    response = get_html(\"https://www.google.com/search?q=\" + query)\n",
        "    results = response.find_all('div', class_=\"tF2Cxc\")\n",
        "    search = response.find_all('div', class_=\"yuRUbf\")\n",
        "    for h in search:\n",
        "      test_res = h.a.get('href')\n",
        "      if test_res.find('crunchbase.com') > 0:\n",
        "        test_res = test_res.replace('people', '')\n",
        "        test_res = test_res.replace('technology', '')\n",
        "        test_res = test_res.replace('signals_and_news', '')\n",
        "        return test_res\n",
        "    return ''\n",
        "\n",
        "\n",
        "def find_between( s, first, last ):\n",
        "    try:\n",
        "        start = s.index( first ) + len( first )\n",
        "        end = s.index( last, start )\n",
        "        return s[start:end]\n",
        "    except ValueError:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "headers = {'User-Agent': UserAgent().chrome}\n",
        "\n",
        "def get_html_request(url):\n",
        "        response = requests.get(url, headers=headers)\n",
        "        return response"
      ]
    }
  ]
}